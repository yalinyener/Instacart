{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Topic:        Project 3\n",
    "# Subject:      Market Basket Analysis of Instacart - Feature Engineering\n",
    "# Date:         04/09/2020\n",
    "# Name:         yalin yener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import patsy\n",
    "import scipy.stats as stats\n",
    "from collections import OrderedDict\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LassoCV, RidgeCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Files and Creating Data Frame\n",
    "aisle = pd.read_csv(\"/Users/yalinyener/GitHub/yalinyener/Instacart/Data/aisles.csv\")\n",
    "departments = pd.read_csv(\"/Users/yalinyener/GitHub/yalinyener/Instacart/Data/departments.csv\")\n",
    "orders = pd.read_csv(\"/Users/yalinyener/GitHub/yalinyener/Instacart/Data/orders.csv\")\n",
    "products = pd.read_csv(\"/Users/yalinyener/GitHub/yalinyener/Instacart/Data/products.csv\")\n",
    "order_products_prior = pd.read_csv('/Users/yalinyener/GitHub/yalinyener/Instacart/Data/order_products__prior.csv')\n",
    "order_products_train = pd.read_csv('/Users/yalinyener/GitHub/yalinyener/Instacart/Data/order_products__train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_products_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_products_train =order_products_train.merge(orders.drop('eval_set',axis=1),on='order_id')\n",
    "order_products_prior =order_products_prior.merge(orders.drop('eval_set',axis=1),on='order_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_products_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_product = (order_products_prior.groupby(['product_id','user_id'],as_index=False) \n",
    "                                          .agg({'order_id':'count'}) \n",
    "                                          .rename(columns={'order_id':'user_product_total_orders'}))\n",
    "\n",
    "train_ids = order_products_train['user_id'].unique() \n",
    "df_X = user_product[user_product['user_id'].isin(train_ids)]\n",
    "df_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_carts = (order_products_train.groupby('user_id',as_index=False)\n",
    "                                      .agg({'product_id':(lambda x: set(x))})\n",
    "                                      .rename(columns={'product_id':'latest_cart'}))\n",
    "\n",
    "df_X = df_X.merge(train_carts, on='user_id')\n",
    "df_X['in_cart'] = (df_X.apply(lambda row: row['product_id'] in row['latest_cart'], axis=1).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.to_pickle(\"./Pickle/df_X_V1.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pcts = df_X.in_cart.value_counts(normalize=True) \n",
    "print(target_pcts)\n",
    "\n",
    "target_pcts.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice data into faeture and target\n",
    "\n",
    "X= df_X.drop(columns=[\"in_cart\",\"latest_cart\",\"product_id\",\"user_id\"])\n",
    "y= df_X.loc[:,\"in_cart\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into train, test and validation (%80 - %20)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Result1\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(lr.predict(X_test),y_test)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(lr.predict(X_test),y_test)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(lr.predict(X_test),y_test)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(lr.predict(X_test),y_test)\n",
    "print('F1 score: %f' % f1)\n",
    "\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(lr.predict(X_test),y_test)\n",
    "print('ROC AUC: %f' % auc)\n",
    "\n",
    "# metrics classification report\n",
    "print(metrics.classification_report(lr.predict(X_test),y_test)\n",
    "\n",
    "\n",
    "# confusion matrix\n",
    "titles_options = [(\"Confusion matrix, without normalization\", None),\n",
    "                  (\"Normalized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(lr, X_test, y_test,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering (Product Features)\n",
    "prod_features = ['product_total_orders','product_avg_add_to_cart_order']\n",
    "df_prod_features = (df_order_products_prior.groupby(['product_id'],as_index=False)\n",
    "                                           .agg(OrderedDict(\n",
    "                                                   [('order_id','nunique'),\n",
    "                                                    ('add_to_cart_order','mean')])))\n",
    "\n",
    "df_prod_features.columns = ['product_id'] + prod_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prod_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_X = df_X.merge(df_prod_features, on='product_id')\n",
    "\n",
    "df_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.to_pickle(\"df_X_V2.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = pd.read_pickle(\"df_X_V2.pickle\")\n",
    "df_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features(df, sample_size=500):\n",
    "    \n",
    "    sample = (df.drop(['product_id','user_id','latest_cart'],axis=1)\n",
    "                .sample(1000, random_state=44)) \n",
    "    sns.pairplot(sample,hue='in_cart', plot_kws=dict(alpha=.3, edgecolor='none'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features(df_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model-2\n",
    "X= df_X.drop(columns=[\"in_cart\",\"latest_cart\",\"product_id\",\"user_id\"])\n",
    "y= df_X.loc[:,\"in_cart\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=10)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Result2\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(lr.predict(X_test),y_test)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(lr.predict(X_test),y_test)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(lr.predict(X_test),y_test)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(lr.predict(X_test),y_test)\n",
    "print('F1 score: %f' % f1)\n",
    " # kappa\n",
    "kappa = cohen_kappa_score(lr.predict(X_test),y_test)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(lr.predict(X_test),y_test)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "titles_options = [(\"Confusion matrix, without normalization\", None),\n",
    "                  (\"Normalized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(lr, X_test, y_test,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = ['user_total_orders','user_avg_cartsize','user_total_products','user_avg_days_since_prior_order']\n",
    "\n",
    "df_user_features = (df_order_products_prior.groupby(['user_id'],as_index=False)\n",
    "                                           .agg(OrderedDict(\n",
    "                                                   [('order_id',['nunique', (lambda x: x.shape[0] / x.nunique())]),\n",
    "                                                    ('product_id','nunique'),\n",
    "                                                    ('days_since_prior_order','mean')])))\n",
    "\n",
    "df_user_features.columns = ['user_id'] + user_features\n",
    "df_user_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_X = df_X.merge(df_user_features, on='user_id')\n",
    "df_X = df_X.dropna() # note that this is naive NaN handling for simplicity\n",
    "df_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.to_pickle(\"df_X_V3.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = pd.read_pickle(\"df_X_V3.pickle\")\n",
    "df_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features(df_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model-3\n",
    "X= df_X.drop(columns=[\"in_cart\",\"latest_cart\",\"product_id\",\"user_id\"])\n",
    "y= df_X.loc[:,\"in_cart\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=10)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Result3\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(lr.predict(X_test),y_test)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(lr.predict(X_test),y_test)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(lr.predict(X_test),y_test)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(lr.predict(X_test),y_test)\n",
    "print('F1 score: %f' % f1)\n",
    " \n",
    "# kappa\n",
    "kappa = cohen_kappa_score(lr.predict(X_test),y_test)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(lr.predict(X_test),y_test)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "titles_options = [(\"Confusion matrix, without normalization\", None),\n",
    "                  (\"Normalized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(lr, X_test, y_test,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prod_features = ['user_product_avg_add_to_cart_order']\n",
    "\n",
    "df_user_prod_features = (df_order_products_prior.groupby(['product_id','user_id'],as_index=False) \\\n",
    "                                                .agg(OrderedDict(\n",
    "                                                     [('add_to_cart_order','mean')])))\n",
    "\n",
    "df_user_prod_features.columns = ['product_id','user_id'] + user_prod_features \n",
    "df_user_prod_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_X = df_X.merge(df_user_prod_features,on=['user_id','product_id'])\n",
    "df_X['user_product_order_freq'] = df_X['user_product_total_orders'] / df_X['user_total_orders'] \n",
    "df_X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.to_pickle(\"df_X_V4.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = pd.read_pickle(\"df_X_V4.pickle\")\n",
    "df_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_X = pd.read_pickle(\"df_X_V4.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model-4\n",
    "X= df_X.drop(columns=[\"in_cart\",\"latest_cart\",\"product_id\",\"user_id\"])\n",
    "y= df_X.loc[:,\"in_cart\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=10)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Result4\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(lr.predict(X_test),y_test)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(lr.predict(X_test),y_test)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(lr.predict(X_test),y_test)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(lr.predict(X_test),y_test)\n",
    "print('F1 score: %f' % f1)\n",
    " \n",
    "# kappa\n",
    "kappa = cohen_kappa_score(lr.predict(X_test),y_test)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(lr.predict(X_test),y_test)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "titles_options = [(\"Confusion matrix\", None),\n",
    "                  (\"Normalized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(lr, X_test, y_test,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Adding Product Category\n",
    "prod_dep = products.merge(departments, on=\"department_id\")\n",
    "prod_dep = prod_dep[[\"product_id\",\"department\"]]\n",
    "df_X = df_X.merge(prod_dep,on=\"product_id\")\n",
    "df_X = pd.concat([df_X.drop('department',axis=1),pd.get_dummies(df_X[\"department\"])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.to_pickle(\"df_X_V5.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = pd.read_pickle(\"df_X_V5.pickle\")\n",
    "df_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features(df_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 5\n",
    "X= df_X.drop(columns=[\"in_cart\",\"latest_cart\",\"product_id\",\"user_id\"])\n",
    "y= df_X.loc[:,\"in_cart\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=10)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Result5\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(lr.predict(X_test),y_test)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(lr.predict(X_test),y_test)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(lr.predict(X_test),y_test)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(lr.predict(X_test),y_test)\n",
    "print('F1 score: %f' % f1)\n",
    " \n",
    "# kappa\n",
    "kappa = cohen_kappa_score(lr.predict(X_test),y_test)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(lr.predict(X_test),y_test)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "titles_options = [(\"Confusion matrix\", None),\n",
    "                  (\"Normalized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(lr, X_test, y_test,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Aisle Category\n",
    "prod_aisle = products.merge(aisle, on=\"aisle_id\")\n",
    "df_X = df_X.merge(prod_aisle,on=\"product_id\")\n",
    "df_X = pd.concat([df_X.drop('aisle',axis=1),pd.get_dummies(df_X[\"aisle\"])],axis=1)\n",
    "df_X = df_X.drop(columns=[\"product_name\",\"aisle_id\",\"department_id\"])\n",
    "df_X.to_pickle(\"df_X_V6.pickle\")\n",
    "\n",
    "#Model-6\n",
    "X= df_X.drop(columns=[\"in_cart\",\"latest_cart\",\"product_id\",\"user_id\"])\n",
    "y= df_X.loc[:,\"in_cart\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=10)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "#Result6\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(lr.predict(X_test),y_test)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(lr.predict(X_test),y_test)\n",
    "print('Precision: %f' % precision)\n",
    "\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(lr.predict(X_test),y_test)\n",
    "print('Recall: %f' % recall)\n",
    "\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(lr.predict(X_test),y_test)\n",
    "print('F1 score: %f' % f1)\n",
    " \n",
    "# kappa\n",
    "kappa = cohen_kappa_score(lr.predict(X_test),y_test)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(lr.predict(X_test),y_test)\n",
    "print('ROC AUC: %f' % auc)\n",
    "\n",
    "# confusion matrix\n",
    "titles_options = [(\"Confusion matrix\", None),\n",
    "                  (\"Normalized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(lr, X_test, y_test,\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_dow = orders[[\"user_id\",\"order_dow\"]]\n",
    "df_X = df_X.merge(order_dow,on=\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.to_pickle(\"df_X_V7.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = pd.concat([df_X.drop('order_dow',axis=1),pd.get_dummies(df_X[\"order_dow\"])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Feature Engineering 7\n",
    "\n",
    "#Adding Day of Week\n",
    "order_dow = orders[[\"user_id\",\"order_dow\"]]\n",
    "df_X = df_X.merge(order_dow,on=\"user_id\")\n",
    "df_X = pd.concat([df_X.drop('order_dow',axis=1),pd.get_dummies(df_X[\"order_dow\"])],axis=1)\n",
    "df_X = df_X.drop(columns=[\"product_name\",\"aisle_id\",\"department_id\"])\n",
    "\n",
    "#Model-7\n",
    "X= df_X.drop(columns=[\"in_cart\",\"latest_cart\",\"product_id\",\"user_id\"])\n",
    "y= df_X.loc[:,\"in_cart\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=10)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "#Result-7\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(lr.predict(X_test),y_test)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(lr.predict(X_test),y_test)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(lr.predict(X_test),y_test)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(lr.predict(X_test),y_test)\n",
    "print('F1 score: %f' % f1)\n",
    " # kappa\n",
    "kappa = cohen_kappa_score(lr.predict(X_test),y_test)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(lr.predict(X_test),y_test)\n",
    "print('ROC AUC: %f' % auc)\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(lr.predict(X_test),y_test)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding Hour"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
